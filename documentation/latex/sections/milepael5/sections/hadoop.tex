\subsection{Endringer på nettsiden}

Vi fant ut i denne milepælen at dynamisk brukerinput ville være vanskelig å inkorporere i noen av aggregeringene, som f.eks land-aggregeringene i dokumentdatabasene. Derfor ville det vært vesentlig mindre brukerinteraksjon på nettsiden.

\subsection{HDFS}
\subsubsection{Listing/remove}
hadoop fs -ls hdfs:///		-rm

\subsubsection{Lese fra HDFS}
\code{Scala}{code/milepael5/hdfsRead.scala}

\subsubsection{Kopiere fra local til HDFS}

$hadoop fs -copyFromLocal country-profiles.parquet /country-profiles.parquet \newline
hadoop fs -copyFromLocal university_write.parquet /university-write.parquet \newline
hadoop fs -copyFromLocal student-performance.parquet /student-performance.parquet \newline
hadoop fs -copyFromLocal reign_write.parquet /reign-write.parquet\newline
hadoop fs -copyFromLocal regime_write.parquet /regime-write.parquet\newline
hadoop fs -copyFromLocal leader_write.parquet /leader-write.parquet\newline
hadoop fs -copyFromLocal election_write.parquet /election-write.parquet\newline
//-copyToLocal for motsatt
$

\subsubsection{Hva skjer egentlig?}
Det første vi gjør er å kopiere de lokale parquet-filene til HDFS, det vil fungere ca slik:


\begin{enumerate}
    \item ber namenode om å opprette en fil. Namenode vil returnere en liste over noder for å lage replika blokker (første replika er lokalt plassert, andre på en annen rack, tredje på samme rack som replika 2)
    \subitem Bare en replika per node 
    \subitem To replika per rack(om det er nok racks)
    \item blokkdata skrives da til første node i namenode listen
    \item ber namenode å hente ut neste sett med blokklokasjoner, skriv blokken
    \item informerer namenode om at filen er ferdig skrevet og gjør filen tilgjengelig
  \end{enumerate}


Nå som det er lagret på noder i HDFS kan vi da hente ut parquet-filene derfra via Spark med read-kommando og gjøre aggregeringer.

\begin{enumerate}
    \item I average-grades.csv aggregeringen(aggregering 1) henter først ut hele listen fra HDFS og legger det i en dataframe.
    \item Etter det lages det to Row() elementer som holder på hver sin del av dataen, en for fars utdanning og en for mors
    \item . Etter det gjør vi en joinWith på dataen, og legger de sammen basert på verdien i utdanningsnivå som er 0-4.
    \item Når har vi en dataframe bestående av to structs som vi bytter navn på
    \item Vi "flater" så ut struct-typen som har blitt skapt av den tidligere joinWith for å pakke ut til to hovedgrupper.
    \item Til slutt skrives filen til disk som csv fil, eller den kan skrives til HDFS.
  \end{enumerate}
